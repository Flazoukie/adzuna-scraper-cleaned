name: Analyze Scraped Data

on:
  workflow_dispatch:

jobs:
  analyze:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout scraper repo
        uses: actions/checkout@v3

      - name: Setup Python 3.12
        uses: actions/setup-python@v4
        with:
          python-version: 3.12

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests jupyter nbconvert

      - name: List data directory contents for debug
        run: |
          echo "Current directory: $(pwd)"
          ls -l data

      - name: Execute analysis notebook
        run: |
          jupyter nbconvert --to notebook --execute analyze_jobs.ipynb --output output.ipynb --ExecutePreprocessor.timeout=600 --ExecutePreprocessor.allow_errors=True

      - name: Clone data-blog repository
        env:
          BLOG_REPO_TOKEN: ${{ secrets.BLOG_REPO_TOKEN }}
        run: |
          git clone https://x-access-token:${BLOG_REPO_TOKEN}@github.com/Flazoukie/data-blog.git data-blog

      - name: Copy analysis results to data-blog repo
        run: |
          # Adjust 'results' below if your notebook saves files elsewhere
          cp -r results/* data-blog/results/

      - name: Commit and push results to data-blog
        run: |
          cd data-blog
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add results/*
          git commit -m "Add latest analysis results $(date +'%Y-%m-%d')" || echo "No changes to commit"
          git push
